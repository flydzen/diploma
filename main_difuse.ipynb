{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from utils.svg import SVG\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "\n",
    "import utils.dataloader as dl\n",
    "from svglib.svglib import svg2rlg\n",
    "from reportlab.graphics import renderPM\n",
    "import shutil\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "SVG.ENCODE_HEIGHT = 80\n",
    "# fonts_number = 100\n",
    "fonts_number = None\n",
    "\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "<################################################################################>: 100.% [15147 / 15147]\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "dl.load_data(fonts_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>font</th>\n",
       "      <th>letter</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!crass_roots_ofl</td>\n",
       "      <td>a</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!crass_roots_ofl</td>\n",
       "      <td>b</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!crass_roots_ofl</td>\n",
       "      <td>c</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!crass_roots_ofl</td>\n",
       "      <td>d</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!crass_roots_ofl</td>\n",
       "      <td>e</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337538</th>\n",
       "      <td>çarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337539</th>\n",
       "      <td>çarsi</td>\n",
       "      <td>w</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337540</th>\n",
       "      <td>çarsi</td>\n",
       "      <td>x</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337541</th>\n",
       "      <td>çarsi</td>\n",
       "      <td>y</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337542</th>\n",
       "      <td>çarsi</td>\n",
       "      <td>z</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337543 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    font letter  \\\n",
       "0       !crass_roots_ofl      a   \n",
       "1       !crass_roots_ofl      b   \n",
       "2       !crass_roots_ofl      c   \n",
       "3       !crass_roots_ofl      d   \n",
       "4       !crass_roots_ofl      e   \n",
       "...                  ...    ...   \n",
       "337538             çarsi      v   \n",
       "337539             çarsi      w   \n",
       "337540             çarsi      x   \n",
       "337541             çarsi      y   \n",
       "337542             çarsi      z   \n",
       "\n",
       "                                                     data  \n",
       "0       [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1       [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2       [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3       [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4       [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "...                                                   ...  \n",
       "337538  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "337539  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "337540  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "337541  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "337542  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "\n",
       "[337543 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Encoding data')\n",
    "stored_path = Path(f'data/data_{SVG.ENCODE_HEIGHT}_{fonts_number}.json')\n",
    "if stored_path.exists():\n",
    "    data = pd.read_json(str(stored_path))\n",
    "    # data['data'] = data['data'].apply(lambda x: np.array(x))\n",
    "else:\n",
    "    data = dl.get_data(fonts_number)\n",
    "    data.to_json(str(stored_path))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение даталоадеров\n",
    "`Dataloader` для букв\n",
    "\n",
    "`DataloaderRows` для линий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, df: pd.DataFrame, test_size=0.1, shuffle=False, batch_size=24):\n",
    "        if shuffle:\n",
    "            df = df.sample(frac=1).reset_index(drop=True)\n",
    "        xs = np.array(df['data'].to_list(), dtype=np.float32)\n",
    "        ys = df['letter'].to_numpy()\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(xs, ys, test_size=test_size, shuffle=shuffle)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def iterate(self):\n",
    "        bs = self.batch_size\n",
    "        for i in range(len(self.x_train) // bs):\n",
    "            yield self.x_train[i * bs: (i + 1) * bs], self.y_train[i * bs: (i + 1) * bs]\n",
    "\n",
    "    def iterate_test(self):\n",
    "        yield self.x_test, self.y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train) // self.batch_size + int(len(self.x_train) % self.batch_size > 0)\n",
    "    \n",
    "class DataloaderRows:\n",
    "    def __init__(self, df: pd.DataFrame, test_size=0.1, shuffle=False, batch_size=24):\n",
    "        if shuffle:\n",
    "            df = df.sample(frac=1).reset_index(drop=True)\n",
    "        xs = np.array(df['data'].to_list(), dtype=np.float32)\n",
    "        xs = xs.reshape((-1, SVG.ENCODE_WIDTH))\n",
    "        self.x_train, self.x_test = train_test_split(xs, test_size=test_size, shuffle=shuffle)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def iterate(self):\n",
    "        bs = self.batch_size\n",
    "        for i in range(len(self.x_train) // bs):\n",
    "            yield self.x_train[i * bs: (i + 1) * bs]\n",
    "\n",
    "    def iterate_test(self):\n",
    "        yield self.x_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train) // self.batch_size + int(len(self.x_train) % self.batch_size > 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataloader = Dataloader(data, test_size=0.15, shuffle=True)\n",
    "dataloader_rows = DataloaderRows(data, test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def save_sampled(x: np.ndarray, name, close=True):\n",
    "    file = Path('imgs') / name\n",
    "    file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    svg = SVG.decode(x, path=file)\n",
    "    svg.dump_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "save_sampled(dataloader.x_test[3], 'test_print.svg', close=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение энкодеров\n",
    "`AE` - автоэнкодер\n",
    "\n",
    "`CAE` - автоэнкодер с условием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnAndDropout(nn.Module):\n",
    "    def __init__(self, features, p=0.15):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features=features)\n",
    "        self.do = nn.Dropout(p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.do(self.bn(x))\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, f_in, f_out):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(f_in, f_out),\n",
    "            nn.Tanh(),\n",
    "            # BnAndDropout(f_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        # TODO: Double check the ordering here\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encode = True\n",
    "        self.decode = True\n",
    "        \n",
    "        self.encoder = []\n",
    "        for i in range(len(params) - 1):\n",
    "            self.encoder.append(Block(params[i], params[i + 1]))\n",
    "        \n",
    "        self.decoder = []\n",
    "        for i in range(len(params) - 1, 0, -1):\n",
    "            self.decoder.append(Block(params[i], params[i - 1]))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*self.encoder)\n",
    "        self.decoder = nn.Sequential(*self.decoder)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.encode:\n",
    "            x = self.encoder(x)\n",
    "        if self.decode:\n",
    "            x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self):\n",
    "        def _inner(y_hat, y):\n",
    "            return ((y - y_hat)**2).mean(axis=0).sum()\n",
    "\n",
    "        return _inner\n",
    "\n",
    "\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self, params, in_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        encoder_params = params[:]\n",
    "        encoder_params[0] += in_labels\n",
    "        \n",
    "        decoder_params = params[::-1]\n",
    "        decoder_params[0] += in_labels\n",
    "\n",
    "        self.encoder = []\n",
    "        for i in range(len(encoder_params) - 1):\n",
    "            self.encoder.append(Block(encoder_params[i], encoder_params[i + 1]))\n",
    "        \n",
    "        self.decoder = []\n",
    "        self.decoder.append(Block(decoder_params[0], decoder_params[1]))\n",
    "        for i in range(1, len(decoder_params) - 1):\n",
    "            self.decoder.append(Block(decoder_params[i] * 2, decoder_params[i + 1]))\n",
    "\n",
    "        self.encoder = nn.ParameterList(self.encoder)\n",
    "        self.decoder = nn.ParameterList(self.decoder)\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        shape = x.shape\n",
    "        \n",
    "        x = x.view(shape[0], -1)\n",
    "        x = torch.cat((x, labels), 1)\n",
    "        accumulate = []\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            accumulate.append(x)\n",
    "        accumulate.pop()\n",
    "        \n",
    "        x = torch.cat((x, labels), 1)\n",
    "        x = self.decoder[0](x)\n",
    "        \n",
    "        for layer in self.decoder[1:]:\n",
    "            connection = accumulate.pop()\n",
    "            x = torch.cat((x, connection), 1)\n",
    "            x = layer(x)\n",
    "        x = x.view(shape[0], shape[1], -1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def loss(self):\n",
    "        def _inner(y_hat, y):\n",
    "            return ((y - y_hat)**2).mean(axis=0).sum()\n",
    "\n",
    "        return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_HOT_LEN = len(dl.GLYPH_FILTER)\n",
    "one_hot_rules = {\n",
    "    glyph: one_hot\n",
    "    for glyph, one_hot in zip(\n",
    "        dl.GLYPH_FILTER, \n",
    "        range(0, ONE_HOT_LEN),\n",
    "    )\n",
    "}\n",
    "\n",
    "def labels2num(labels):\n",
    "    return torch.Tensor([one_hot_rules[i] for i in labels]).long()\n",
    "\n",
    "def labels2one_hot(labels):\n",
    "    return F.one_hot(labels2num(labels), num_classes=ONE_HOT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "interval = len(dataloader) / 6\n",
    "\n",
    "train_ts, train_loss = [], []\n",
    "test_ts, test_loss = [], []\n",
    "\n",
    "\n",
    "def show_progress(t, epochs, save_to=None, info: dict | None = None):\n",
    "    display.clear_output(wait=True)\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, constrained_layout=True, figsize=(12, 10))\n",
    "    fig.suptitle(f'Epoch {t:3.3f} / {epochs}', fontsize=16)\n",
    "    \n",
    "    last_size = 0.5\n",
    "    \n",
    "    for ax, msg in zip((ax1, ax2), ('', f'last {int(last_size*100)}%')):\n",
    "        title = f'loss {msg}'\n",
    "        if info is not None:\n",
    "            title += ' | ' + ' | '.join(f'{key}: {value}' for key, value in info.items())\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('time (epochs)')\n",
    "        ax.set_ylabel('loss')\n",
    "    last_train = str(train_loss[-1]) if len(train_loss) > 0 else ''\n",
    "    last_test = str(test_loss[-1]) if len(test_loss) > 0 else ''\n",
    "    \n",
    "    ax1.plot(train_ts, train_loss, c='darkblue', lw=3, label=f'train: {last_train}')\n",
    "    ax1.plot(test_ts, test_loss, c='green', marker='o', lw=5, label=f'test: {last_test}')\n",
    "    \n",
    "    ax2.plot(train_ts[-int(len(train_ts)*last_size):], train_loss[-int(len(train_loss)*last_size):], c='darkblue', lw=3, label=f'train: {last_train}')\n",
    "    ax2.plot(test_ts[-int(len(test_ts)*last_size):], test_loss[-int(len(test_loss)*last_size):], c='green', marker='o', lw=5, label=f'test: {last_test}')\n",
    "    \n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    if save_to is None:\n",
    "        plt.show() \n",
    "    else:\n",
    "        plt.savefig(save_to)\n",
    "        plt.close()\n",
    "    \n",
    "def train_cae(epoch, epochs, dataloader, model, loss_fn, optimizer, scheduler, pbar=None, show=True):\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (inp_data, labels) in enumerate(dataloader.iterate()):\n",
    "        inp_data = torch.Tensor(inp_data).to(device)        \n",
    "        labels = labels2one_hot(labels).to(device)\n",
    "\n",
    "        output = model(inp_data, labels)\n",
    "        loss = loss_fn(output, inp_data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % interval == 0:\n",
    "            t = epoch + (batch + 1) / num_batches\n",
    "            train_ts.append(t)\n",
    "            train_loss.append(loss.item())\n",
    "            if show:                \n",
    "                show_progress(t, epochs, info={'lr': scheduler.get_last_lr()[0]})\n",
    "            if pbar is not None:\n",
    "                pbar.refresh()\n",
    "    scheduler.step()        \n",
    "    \n",
    "def test_cae(epoch, epochs, dataloader, model, loss_fn, show=True):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    tmp_test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for inp_data, labels in dataloader.iterate_test():\n",
    "            inp_data = torch.Tensor(inp_data).to(device)\n",
    "            labels = labels2one_hot(labels).to(device)\n",
    "\n",
    "            result = model(inp_data, labels)\n",
    "            loss = loss_fn(result, inp_data)\n",
    "\n",
    "            tmp_test_loss.append(loss.item())\n",
    "            \n",
    "    test_ts.append(epoch)\n",
    "    test_loss.append(np.mean(tmp_test_loss))\n",
    "    if show:\n",
    "        show_progress(epoch, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae(epoch, epochs, dataloader, model, loss_fn, optimizer, scheduler, pbar=None, show=True):\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, inp_data in enumerate(dataloader.iterate()):\n",
    "        inp_data = torch.Tensor(inp_data).to(device)\n",
    "\n",
    "        output = model(inp_data)\n",
    "        loss = loss_fn(output, inp_data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % interval == 0:\n",
    "            t = epoch + (batch + 1) / num_batches\n",
    "            train_ts.append(t)\n",
    "            train_loss.append(loss.item())\n",
    "            if show:                \n",
    "                show_progress(t, epochs, info={'lr': scheduler.get_last_lr()[0]})\n",
    "            if pbar is not None:\n",
    "                pbar.refresh()\n",
    "    scheduler.step()        \n",
    "    \n",
    "def test_ae(epoch, epochs, dataloader, model, loss_fn, show=True):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    tmp_test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for images in dataloader.iterate_test():\n",
    "            images = torch.Tensor(images).to(device)\n",
    "\n",
    "            decoded = model(images)\n",
    "            loss = loss_fn(decoded, images)\n",
    "\n",
    "            tmp_test_loss.append(loss.item())\n",
    "            \n",
    "    test_ts.append(epoch)\n",
    "    test_loss.append(np.mean(tmp_test_loss))\n",
    "    if show:\n",
    "        show_progress(epoch, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "\n",
    "def run_maker(model_type):\n",
    "    is_cae =  model_type == 'cae'\n",
    "    model_char = 'c' if is_cae else ''\n",
    "    def _inner(model, dataloader, optimizer, scheduler, epochs, params, batch_size, _epoch=0, run_name=None, trial=None):\n",
    "        global epoch\n",
    "\n",
    "        if run_name is None:\n",
    "            run_name = f'run_size{SVG.ENCODE_HEIGHT}_{model_char}ae_{\",\".join(map(str, params))}'\n",
    "\n",
    "        save_folder = Path(f'models_{model_char}ae') / run_name\n",
    "        loss_img_path = str(save_folder / '_loss.png')\n",
    "        save_folder.mkdir(parents=True, exist_ok=True)\n",
    "        plt.clf()\n",
    "        file_format = 'svg'\n",
    "        max_epoch = epoch + epochs\n",
    "        loss_fn = model.loss()\n",
    "        dataloader.batch_size = batch_size\n",
    "\n",
    "        if trial is None:\n",
    "            pbar = trange(epoch, max_epoch)\n",
    "            rng = pbar\n",
    "        else:\n",
    "            pbar = None\n",
    "            rng = range(epoch, max_epoch)\n",
    "        for _epoch in rng:\n",
    "            \n",
    "            if is_cae:\n",
    "                train_fn = train_cae\n",
    "                test_fn = test_cae\n",
    "            else:\n",
    "                train_fn = train_ae\n",
    "                test_fn = test_ae\n",
    "                \n",
    "            train_fn(_epoch, max_epoch, dataloader, model, loss_fn, optimizer, scheduler, pbar, show=trial is None)\n",
    "            test_fn(_epoch + 1, max_epoch, dataloader, model, loss_fn, show=trial is None)\n",
    "                \n",
    "            torch.save(model.state_dict(), save_folder / 'ckpt.pt')\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            if trial is not None:\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "            else:\n",
    "                # if is_cae:\n",
    "#                     with torch.no_grad():\n",
    "#                         num = np.random.randint(0, len(dataloader.x_test))\n",
    "\n",
    "#                         image = torch.tensor(dataloader.x_test[num].reshape((1, SVG.ENCODE_HEIGHT, LINE_WIDTH))).to(device)\n",
    "#                         label = labels2one_hot([dataloader.y_test[num]]).to(device)\n",
    "#                         sample = model(image, label)[0]\n",
    "#                         save_sampled(dataloader.x_test[num], f'{run_name}/test/{_epoch}_{dataloader.y_test[num]}_orig.{file_format}')\n",
    "#                         save_sampled(sample.cpu().detach().numpy(), f'{run_name}/test/{_epoch}_{dataloader.y_test[num]}_gen.{file_format}')\n",
    "\n",
    "#                         image = torch.tensor(dataloader.x_train[num].reshape((1, SVG.ENCODE_HEIGHT, SVG.ENCODE_WIDTH))).to(device)\n",
    "#                         label = labels2one_hot([dataloader.y_train[num]]).to(device)\n",
    "#                         sample = model(image, label)[0]\n",
    "#                         save_sampled(dataloader.x_train[num], f'{run_name}/train/{_epoch}_{dataloader.y_test[num]}_orig.{file_format}')\n",
    "#                         save_sampled(sample.cpu().detach().numpy(), f'{run_name}/train/{_epoch}_{dataloader.y_test[num]}_gen.{file_format}')\n",
    "                epoch = _epoch + 1\n",
    "            show_progress(_epoch + 1, max_epoch, loss_img_path, info={'params':params, 'lr': scheduler.get_last_lr()[0]})\n",
    "\n",
    "    return _inner\n",
    "\n",
    "\n",
    "run_cae = run_maker('cae')\n",
    "run_ae = run_maker('ae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_maker(model_type):\n",
    "    is_cae =  model_type == 'cae'\n",
    "    model_char = 'c' if is_cae else ''\n",
    "\n",
    "    def _inner(params, lr, weight_decay=2e-5, step_size=1):\n",
    "        global train_ts, train_loss, test_ts, test_loss, epoch\n",
    "\n",
    "        if is_cae:\n",
    "            model = CAE(params, ONE_HOT_LEN).to(device)\n",
    "        else:\n",
    "            model = AE(params).to(device)\n",
    "            \n",
    "        loss_fn = model.loss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.95)\n",
    "\n",
    "        train_ts, train_loss = [], []\n",
    "        test_ts, test_loss = [], []\n",
    "        epoch = 0\n",
    "\n",
    "        return model, optimizer, scheduler, loss_fn\n",
    "\n",
    "    return _inner\n",
    "    \n",
    "setup_cae = setup_maker('cae')\n",
    "setup_ae = setup_maker('ae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Поиск конфигурации модели для кодирования линий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-18 19:23:50,745]\u001b[0m Trial 49 finished with value: 9.119536116486415e-05 and parameters: {'lr': 0.00013387223829575858, 'p0': 20, 'p1': 17, 'p2': 14}. Best is trial 44 with value: 6.124428604674469e-05.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_for_search(trial):\n",
    "    lr = trial.suggest_float('lr', 1e-6, 1e-3, log=True)\n",
    "    params = [\n",
    "        SVG.ENCODE_WIDTH,\n",
    "        trial.suggest_int('p1', 10, 25),\n",
    "        trial.suggest_int('p2', 8, 20),\n",
    "        trial.suggest_int('p3', 4, 10),\n",
    "    ]\n",
    "\n",
    "    for i in range(3):\n",
    "        params.append(trial.suggest_int(f'p{i}', 4, 20))\n",
    "    \n",
    "    model, optimizer, scheduler, loss_fn = setup_ae(\n",
    "        params=params,\n",
    "        lr=lr,\n",
    "        weight_decay=5e-5,\n",
    "    )\n",
    "    run_ae(\n",
    "        model=model, \n",
    "        dataloader=dataloader_rows, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        epochs=4,\n",
    "        params=params,\n",
    "        batch_size=2048,\n",
    "        run_name='temp',\n",
    "        trial=trial,\n",
    "    )\n",
    "    return test_loss[-1] + max(test_loss[-1] - train_loss[-1], 0) ** 2 \n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=\"sqlite:///db.sqlite3\",\n",
    "    study_name=\"ae_lr_3_layers_4_epoch\"\n",
    ")\n",
    "\n",
    "study.optimize(run_for_search, n_trials=50, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем кодировщик линий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LINE_WIDTH = 10\n",
    "params = [SVG.ENCODE_WIDTH, 19, 15, LINE_WIDTH]\n",
    "\n",
    "model_rows, optimizer_rows, scheduler_rows, loss_fn_rows = setup_ae(\n",
    "    params=params,\n",
    "    lr=6e-4,\n",
    "    weight_decay=3e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:32<00:00, 70.83s/it]\n"
     ]
    }
   ],
   "source": [
    "run_ae(\n",
    "    model=model_rows, \n",
    "    dataloader=dataloader_rows,\n",
    "    optimizer=optimizer_rows,\n",
    "    scheduler=scheduler_rows,\n",
    "    epochs=3,\n",
    "    params=params,\n",
    "    batch_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодируем все линии в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 337543/337543 [02:46<00:00, 2025.09it/s]\n"
     ]
    }
   ],
   "source": [
    "model_rows.decode = False\n",
    "model_rows.eval()\n",
    "encoded = []\n",
    "with torch.no_grad():\n",
    "    to_encode = np.array(data['data'].to_list(), dtype=np.float32)\n",
    "    for batch in tqdm(to_encode):\n",
    "        batch = torch.Tensor(batch).to(device)\n",
    "        encoded.append(model_rows(batch).cpu().detach().numpy())\n",
    "        \n",
    "enc_data = data.copy()\n",
    "enc_data['data'] = encoded\n",
    "\n",
    "enc_dataloader = Dataloader(enc_data, test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [SVG.ENCODE_HEIGHT * LINE_WIDTH, 2780, 1820, 1260, 1104, 865, 350]\n",
    "\n",
    "model, optimizer, scheduler, loss_fn = setup_cae(\n",
    "    params=params,\n",
    "    lr=2e-4,\n",
    "    weight_decay=6e-6,\n",
    "    step_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:40<00:00, 40.54s/it]\n"
     ]
    }
   ],
   "source": [
    "run_cae(\n",
    "    model=model, \n",
    "    dataloader=enc_dataloader, \n",
    "    optimizer=optimizer, \n",
    "    scheduler=scheduler, \n",
    "    epochs=1,\n",
    "    params=params,\n",
    "    batch_size=128,\n",
    "    # run_name=f'run_relative_01_tanh_size{SVG.ENCODE_HEIGHT}_{\"c\" if model.vae else \"\"}vae_{\",\".join(map(str, params))}',\n",
    "    run_name=f'run_encoded_tanh_size{SVG.ENCODE_HEIGHT}_ucae_{\",\".join(map(str, params))}',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
